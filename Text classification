import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

sentences = [
    "I love this movie", 
    "This film was terrible", 
    "What a fantastic performance", 
    "Worst movie ever", 
    "It was okay, not great", 
    "Absolutely loved it",
    "I hated it so much", 
    "A masterpiece", 
    "Not my type of film", 
    "The story was boring"
]

labels = [1, 0, 1, 0, 0, 1, 0, 1, 0, 0]

vocab_size = 10000
embedding_dim = 16
max_length = 10
trunc_type = 'post'
padding_type = 'post'
oov_token = "<OOV>"

training_size = int(len(sentences) * 0.8)
training_sentences = sentences[:training_size]
training_labels = labels[:training_size]
validation_sentences = sentences[training_size:]
validation_labels = labels[training_size:]

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)
tokenizer.fit_on_texts(training_sentences)

training_sequences = tokenizer.texts_to_sequences(training_sentences)
training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)

validation_sequences = tokenizer.texts_to_sequences(validation_sentences)
validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

num_epochs = 30
model.fit(
    np.array(training_padded), 
    np.array(training_labels), 
    epochs=num_epochs, 
    validation_data=(np.array(validation_padded), np.array(validation_labels))
)

test_sentence = ["granny starting to fear spiders in the garden might be real"]
test_seq = tokenizer.texts_to_sequences(test_sentence)
test_pad = pad_sequences(test_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)

prediction = model.predict(test_pad)
print(f"Prediction: {prediction[0][0]:.4f}")
